{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWYb8YnbhELqhwxy1sKGwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HananeNourMoussa/darija-ner/blob/master/Experiment_2_BERT_RNN_Dense_Layer(Softmax).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Experiment Parameters:"
      ],
      "metadata": {
        "id": "4oqGqBDabRsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UBC-NLP/ARBERT\n",
        "# UBC-NLP/MARBERT\n",
        "# bert-base-multilingual-cased\n",
        "# SI2M-Lab/DarijaBERT\n",
        "# CAMeL-Lab/bert-base-arabic-camelbert-da\n",
        "# CAMeL-Lab/bert-base-arabic-camelbert-msa\n",
        "# CAMeL-Lab/bert-base-arabic-camelbert-mix\n",
        "# aubmindlab/bert-base-arabertv02"
      ],
      "metadata": {
        "id": "laEVBp5LcM9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_default = {\n",
        "    'epochs' : 5,\n",
        "    'batch_size': 8,\n",
        "    'lr_bert': 3e-5,\n",
        "    'lr_rest':1e-4,\n",
        "    'hidden_size': 256,\n",
        "    'num_layers': 1,\n",
        "    'eps': 1e-8,\n",
        "    \"lm\": \"aubmindlab/bert-base-arabertv02\",\n",
        "    \"p1\":0.3,\n",
        "    \"p2\": 0.2,\n",
        "    \"dataset\": \"mixedNERcorp\"\n",
        "}"
      ],
      "metadata": {
        "id": "diioY7XIcvZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 100\n",
        "lm = \"aubmindlab/bert-base-arabertv02\"\n",
        "batch_size = 8\n",
        "freeze_bert = False"
      ],
      "metadata": {
        "id": "MN9ESTlQdSy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "cnuM9nModjty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d6879d-3c1c-43ff-b03b-13d41d475ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 20 00:53:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAM\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "_MFPXW8kdmBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbde998-cc75-47ed-9622-3e9ca8eed303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and Imports:"
      ],
      "metadata": {
        "id": "wf99IPpvdobA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers -q\n",
        "!pip install transformers -q\n",
        "!pip install seqeval -q\n",
        "!pip install torch -q\n",
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "id": "yBWHKD7kdtK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import BertForTokenClassification, AutoTokenizer, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from seqeval.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch import LongTensor\n",
        "import wandb\n",
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "Qn1EcHIZdxGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "dTnWiEnrdzWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "tZ1YC0pYp-zL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1603175-49e8-41bb-b329-0aec168ddd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhanane-n-moussa\u001b[0m (\u001b[33mdarijaner\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing:"
      ],
      "metadata": {
        "id": "o2P9ecWWbbIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "dataset = pd.read_csv(\"/content/gdrive/MyDrive/annotated_corpus/ner-corpus-darija/MixedNERcorp_train.csv\")\n",
        "dataset.pop(\"Unnamed: 0\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "8GUcVDQUd0pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "c8d61a2c-459e-4abb-9f63-d4a2ba4dc424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Sentence    Token    Tag\n",
              "0              0  Uppsala  B-LOC\n",
              "1              0        )      O\n",
              "2              0     هيّا      O\n",
              "3              0     رابع      O\n",
              "4              0     أكبر      O\n",
              "...          ...      ...    ...\n",
              "177821      5957       في      O\n",
              "177822      5957    مختلف      O\n",
              "177823      5957    أنحاء      O\n",
              "177824      5957   المصنع      O\n",
              "177825      5957        .      O\n",
              "\n",
              "[177826 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cca9bf9-59c6-4eb6-adba-c3a665f7ea90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Uppsala</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>)</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>هيّا</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>رابع</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>أكبر</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177821</th>\n",
              "      <td>5957</td>\n",
              "      <td>في</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177822</th>\n",
              "      <td>5957</td>\n",
              "      <td>مختلف</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177823</th>\n",
              "      <td>5957</td>\n",
              "      <td>أنحاء</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177824</th>\n",
              "      <td>5957</td>\n",
              "      <td>المصنع</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177825</th>\n",
              "      <td>5957</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177826 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cca9bf9-59c6-4eb6-adba-c3a665f7ea90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cca9bf9-59c6-4eb6-adba-c3a665f7ea90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cca9bf9-59c6-4eb6-adba-c3a665f7ea90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(lm)"
      ],
      "metadata": {
        "id": "OzxF8QNseHQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceGetter(object):\n",
        "  def __init__(self, data):\n",
        "    #start from the first sentence\n",
        "    self.n_sent = 1\n",
        "    self.data = data\n",
        "    self.empty = False\n",
        "    #aggregate token and tag\n",
        "    agg_func = lambda s:[(to, ta) for to, ta in zip (s[\"Token\"].values.tolist(),\n",
        "                                                     s[\"Tag\"].values.tolist())]\n",
        "    self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
        "    #make list of sentences\n",
        "    self.sentences = [s for s in self.grouped]\n",
        "  def get_next(self):\n",
        "    try:\n",
        "      #get current sentence\n",
        "      s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "      #move to next sentence\n",
        "      self.n_sent += 1\n",
        "      return s\n",
        "    except:\n",
        "      return None"
      ],
      "metadata": {
        "id": "AcKbcz_Sd-Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getter = SentenceGetter(dataset)"
      ],
      "metadata": {
        "id": "E-iPcOtMeFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get tokens of sentences\n",
        "sentences = [[token[0] for token in sentence] for sentence in getter.sentences]\n",
        "sentences[0]"
      ],
      "metadata": {
        "id": "1zK9R890eJ2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce998437-63dd-41b0-9737-ec69d86f5da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Uppsala',\n",
              " ')',\n",
              " 'هيّا',\n",
              " 'رابع',\n",
              " 'أكبر',\n",
              " 'مدينة',\n",
              " 'ف',\n",
              " 'سّويد',\n",
              " 'من',\n",
              " 'بعد',\n",
              " 'سطوكهولم',\n",
              " '،',\n",
              " 'ݣوتنبورݣ',\n",
              " 'ؤ',\n",
              " 'مالمو',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove a nan value that causes errors later\n",
        "sentences_ = list()\n",
        "for sentence in sentences:\n",
        "  sentence_ = list(filter(lambda item: type(item) == str, sentence))\n",
        "  sentences_.append(sentence_)"
      ],
      "metadata": {
        "id": "4Cegocf3eMIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting tags\n",
        "labels = [[s[1] for s in sentence] for sentence in getter.sentences]\n",
        "print(labels[0])"
      ],
      "metadata": {
        "id": "4nDYf31ieOgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8267fa-bff4-4312-b23c-cecd64a31b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding PAD to tags and assigning label numbers\n",
        "tag_values = list(set(dataset[\"Tag\"].values))\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ],
      "metadata": {
        "id": "DD4lPKyHeQIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to tokenize each word into subwords while preserving corresponding labels\n",
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "metadata": {
        "id": "MciiWWJIeTNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pass each sentence at a time to the function\n",
        "tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_, labels)\n",
        "]"
      ],
      "metadata": {
        "id": "XyqDNzikeU9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separate text and labeLslog\n",
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
      ],
      "metadata": {
        "id": "eJHtVo7geW-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text to input ids\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "GpR6X0Joeaaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting encoded tags with PAD included for CLS and SEP tokens\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "QZotcw34ecHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting attention masks to tell model to ignore PADs\n",
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
      ],
      "metadata": {
        "id": "DKf8-5cZeeJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data (sentences) to train, validation, and test\n",
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.2)"
      ],
      "metadata": {
        "id": "tAzAnJjHeew9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to pyTorch tensors\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "metadata": {
        "id": "Z3MPu4O4e6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nUlaa71ae_Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definitions:"
      ],
      "metadata": {
        "id": "bQpJFf7Zbge_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT-BiLSTM-Softmax:"
      ],
      "metadata": {
        "id": "WsyDtm2XfSLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_BiLSTM_SM(nn.Module):\n",
        "    def __init__(self, hidden_size, num_layers, p1, p2, num_classes=len(tag2idx)):\n",
        "        super().__init__()\n",
        "        config = transformers.BertConfig.from_pretrained(lm, hidden_dropout_prob=p1)\n",
        "        self.bert = transformers.BertModel.from_pretrained(lm, config = config)\n",
        "        input_size = self.bert.config.to_dict()['hidden_size']\n",
        "        self.bilstm = nn.LSTM(hidden_size = hidden_size, input_size = input_size, bidirectional = True, num_layers = num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "        self.drop = nn.Dropout(p2)\n",
        "        if freeze_bert == True:\n",
        "          for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "          for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n",
        "    def forward(self, input_ids, attention_mask = None):\n",
        "        s = self.bert(input_ids = input_ids, attention_mask=attention_mask)\n",
        "        s = s['last_hidden_state']\n",
        "        s = self.drop(s)\n",
        "        s, _ = self.bilstm(s)\n",
        "        s = s.reshape(-1, s.shape[2])\n",
        "        s = self.fc(s)\n",
        "        return F.log_softmax(s)"
      ],
      "metadata": {
        "id": "g46HDXtAhnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT-BiGRU-Softmax:"
      ],
      "metadata": {
        "id": "vr_9xXoifZhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_BiGRU_SM(nn.Module):\n",
        "    def __init__(self, hidden_size, num_layers, p1, p2, num_classes=len(tag2idx)):\n",
        "        super().__init__()\n",
        "        config = transformers.BertConfig.from_pretrained(lm, hidden_dropout_prob=p1)\n",
        "        self.bert = transformers.BertModel.from_pretrained(lm, config = config, add_pooling_layer = False)\n",
        "        input_size = self.bert.config.to_dict()['hidden_size']\n",
        "        self.gru = nn.GRU(hidden_size = hidden_size, input_size = input_size, bidirectional = True, num_layers = num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "        self.drop = nn.Dropout(p2)\n",
        "        if freeze_bert == True:\n",
        "          for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "          for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n",
        "    def forward(self, input_ids, attention_mask = None):\n",
        "        s = self.bert(input_ids = input_ids, attention_mask=attention_mask)\n",
        "        s = s['last_hidden_state']\n",
        "        s = self.drop(s)\n",
        "        s, _ = self.gru(s)\n",
        "        s = s.reshape(-1, s.shape[2])\n",
        "        s = self.fc(s)\n",
        "        return F.log_softmax(s)"
      ],
      "metadata": {
        "id": "-RUWkWGxhxyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation:"
      ],
      "metadata": {
        "id": "qdzQIJD2blpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERT_BiLSTM_SM(hidden_size = 256, num_layers = 1, p1 = 0.3, p2 = 0.2)\n",
        "model.cuda()\n",
        "optimizer = optim.AdamW([\n",
        "        {'params': model.bert.parameters(), 'lr':3e-5},\n",
        "        {'params': model.bilstm.parameters(), 'lr':1e-4},\n",
        "        {'params': model.fc.parameters(), 'lr':1e-4}\n",
        "                        ])\n",
        "total_steps = len(train_dataloader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "rJr5iQOBsnwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4536364-1039-4fe6-96ac-05c92b0bae62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(true, pred):\n",
        "  acc = accuracy_score(true, pred)\n",
        "  f1 = f1_score(true, pred)\n",
        "  prec = precision_score(true, pred)\n",
        "  recall = recall_score(true, pred)\n",
        "  report = classification_report(true, pred)\n",
        "  return acc, f1, prec, recall, report"
      ],
      "metadata": {
        "id": "yDIoGPcOlBEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN Code:"
      ],
      "metadata": {
        "id": "L2XdOUF_lvYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataset, total_loss = 0):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  truth = []\n",
        "  with torch.no_grad():\n",
        "      for batch in dataset:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, labels = batch\n",
        "        logits = model(input_ids, input_mask)\n",
        "        loss = criterion(logits, labels.view(-1))\n",
        "        total_loss += loss.item()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "        bs = int((logits.size(dim = 0))/MAX_LEN)\n",
        "        logits = logits.view(bs, MAX_LEN, logits.shape[1])\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis = 2)])\n",
        "        truth.extend(label_ids)\n",
        "  avg_loss = total_loss / len(dataset)\n",
        "  pred_tags = [tag_values[p_i] for p, l in zip(predictions, truth)\n",
        "                                for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "  true_tags = [tag_values[l_i] for l in truth\n",
        "                                for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "  pred = list()\n",
        "  pred.append(pred_tags)\n",
        "  true = list()\n",
        "  true.append(true_tags)\n",
        "  return pred, true, avg_loss"
      ],
      "metadata": {
        "id": "-hmH90T-mIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss = []\n",
        "validation_loss = []\n",
        "tr_accuracies, val_accuracies = [], []\n",
        "tr_f1s, val_f1s = [], []\n",
        "tr_precisions, val_precisions = [], []\n",
        "tr_recalls, val_recalls = [], []\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "def train(config = None):\n",
        "  with wandb.init(project=\"final-results\", config=config_default):\n",
        "    config = wandb.config\n",
        "    # Train the model\n",
        "    for epoch in trange(config.epochs, desc = \"Epoch\"):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            model.zero_grad()\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, labels = batch\n",
        "            logits = model(input_ids, input_mask)\n",
        "            loss = criterion(logits, labels.view(-1))\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            #torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        avg_train_loss = train_loss / len(train_dataloader)\n",
        "        print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "        training_loss.append(avg_train_loss)\n",
        "        #log train loss\n",
        "        wandb.log({'train_loss': avg_train_loss, \"epoch\": epoch})\n",
        "        #performance on training\n",
        "        tr_pred, tr_true, _ = evaluate_model(model, train_dataloader)\n",
        "        tr_acc, tr_f1, tr_prec, tr_recall, tr_report = get_metrics(tr_true, tr_pred)\n",
        "        print(\"Training Accuracy: {}\".format(tr_acc))\n",
        "        tr_accuracies.append(tr_acc)\n",
        "        wandb.log({'train_acc': tr_acc, \"epoch\": epoch})\n",
        "        print(\"Training F1-Score: {}\".format(tr_f1))\n",
        "        tr_f1s.append(tr_f1)\n",
        "        wandb.log({'train_f1': tr_f1, \"epoch\": epoch})\n",
        "        print(\"Training Precision: {}\".format(tr_prec))\n",
        "        tr_precisions.append(tr_prec)\n",
        "        wandb.log({'train_prec': tr_prec, \"epoch\": epoch})\n",
        "        print(\"Training Recall: {}\".format(tr_recall))\n",
        "        tr_recalls.append(tr_recall)\n",
        "        wandb.log({'train_recall': tr_recall, \"epoch\": epoch})\n",
        "        print(\"Training Classification Report:\\n {}\".format(tr_report))\n",
        "        print()\n",
        "        # performance on validation\n",
        "        val_pred, val_true, avg_val_loss = evaluate_model(model, valid_dataloader)\n",
        "        validation_loss.append(avg_val_loss)\n",
        "        wandb.log({'validation_loss': avg_val_loss, \"epoch\": epoch})\n",
        "        val_acc, val_f1, val_prec, val_recall, val_report = get_metrics(val_true, val_pred)\n",
        "        print(\"Validation Accuracy: {}\".format(val_acc))\n",
        "        val_accuracies.append(val_acc)\n",
        "        wandb.log({'val_acc': val_acc, \"epoch\": epoch})\n",
        "        print(\"Validation F1-Score: {}\".format(val_f1))\n",
        "        val_f1s.append(val_f1)\n",
        "        wandb.log({'val_f1': val_f1, \"epoch\": epoch})\n",
        "        print(\"Validation Precision: {}\".format(val_prec))\n",
        "        val_precisions.append(val_prec)\n",
        "        wandb.log({'val_prec': val_prec, \"epoch\": epoch})\n",
        "        print(\"Validation Recall: {}\".format(val_recall))\n",
        "        val_recalls.append(val_recall)\n",
        "        wandb.log({'val_recall': val_recall, \"epoch\": epoch})\n",
        "        print(\"Validation Classification Report:\\n {}\".format(val_report))\n",
        "        overfitting = abs(tr_f1-val_f1)\n",
        "        wandb.log({'overfitting': overfitting, \"epoch\": epoch})\n",
        "        print()\n",
        "  #model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
        "#wandb.agent(sweep_id, train)\n",
        "train()"
      ],
      "metadata": {
        "id": "6JhlPODSmJOU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b472ecf9-2389-4c57-e2ef-6b548e18dd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230420_005449-hina5sn1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/darijaner/final-results/runs/hina5sn1' target=\"_blank\">playful-rain-54</a></strong> to <a href='https://wandb.ai/darijaner/final-results' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/darijaner/final-results' target=\"_blank\">https://wandb.ai/darijaner/final-results</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/darijaner/final-results/runs/hina5sn1' target=\"_blank\">https://wandb.ai/darijaner/final-results/runs/hina5sn1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]<ipython-input-27-cdd061c866b8>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 0.20523667425517267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9117629037792265\n",
            "Training F1-Score: 0.4201214963231376\n",
            "Training Precision: 0.45670811771066655\n",
            "Training Recall: 0.3889619786870149\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.55      0.70      0.62      6509\n",
            "        MISC       0.00      0.00      0.00      3239\n",
            "         ORG       0.00      0.00      0.00      2014\n",
            "         PER       0.29      0.39      0.34      3440\n",
            "\n",
            "   micro avg       0.46      0.39      0.42     15202\n",
            "   macro avg       0.17      0.22      0.19     15202\n",
            "weighted avg       0.30      0.39      0.34     15202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Epoch:  20%|██        | 1/5 [02:32<10:08, 152.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.910935192582371\n",
            "Validation F1-Score: 0.4011291460832745\n",
            "Validation Precision: 0.4396658415841584\n",
            "Validation Recall: 0.36880352971710356\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.53      0.70      0.60      1509\n",
            "        MISC       0.00      0.00      0.00       833\n",
            "         ORG       0.00      0.00      0.00       564\n",
            "         PER       0.30      0.38      0.34       947\n",
            "\n",
            "   micro avg       0.44      0.37      0.40      3853\n",
            "   macro avg       0.17      0.22      0.19      3853\n",
            "weighted avg       0.28      0.37      0.32      3853\n",
            "\n",
            "\n",
            "Average train loss: 0.09099750991773185\n",
            "Training Accuracy: 0.9460198029508358\n",
            "Training F1-Score: 0.614332892998679\n",
            "Training Precision: 0.6168589998673564\n",
            "Training Recall: 0.6118273911327456\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.66      0.82      0.73      6509\n",
            "        MISC       0.59      0.40      0.48      3239\n",
            "         ORG       0.47      0.51      0.49      2014\n",
            "         PER       0.64      0.47      0.54      3440\n",
            "\n",
            "   micro avg       0.62      0.61      0.61     15202\n",
            "   macro avg       0.47      0.44      0.45     15202\n",
            "weighted avg       0.61      0.61      0.60     15202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [05:03<07:35, 151.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9379766141331978\n",
            "Validation F1-Score: 0.5709019091507571\n",
            "Validation Precision: 0.5793693212185996\n",
            "Validation Recall: 0.5626784323903452\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.63      0.80      0.71      1509\n",
            "        MISC       0.45      0.30      0.36       833\n",
            "         ORG       0.47      0.49      0.48       564\n",
            "         PER       0.62      0.46      0.53       947\n",
            "\n",
            "   micro avg       0.58      0.56      0.57      3853\n",
            "   macro avg       0.44      0.41      0.41      3853\n",
            "weighted avg       0.57      0.56      0.55      3853\n",
            "\n",
            "\n",
            "Average train loss: 0.06596324190453645\n",
            "Training Accuracy: 0.9547693740502916\n",
            "Training F1-Score: 0.6961379488504262\n",
            "Training Precision: 0.6836864138018521\n",
            "Training Recall: 0.7090514405999211\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.76      0.86      0.80      6509\n",
            "        MISC       0.60      0.63      0.61      3239\n",
            "         ORG       0.63      0.61      0.62      2014\n",
            "         PER       0.64      0.56      0.60      3440\n",
            "\n",
            "   micro avg       0.68      0.71      0.70     15202\n",
            "   macro avg       0.52      0.53      0.53     15202\n",
            "weighted avg       0.68      0.71      0.69     15202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [07:37<05:05, 152.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9452635146585324\n",
            "Validation F1-Score: 0.6483854433623784\n",
            "Validation Precision: 0.6403442166540116\n",
            "Validation Recall: 0.6566311964702829\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.72      0.83      0.77      1509\n",
            "        MISC       0.51      0.52      0.52       833\n",
            "         ORG       0.61      0.56      0.59       564\n",
            "         PER       0.63      0.55      0.59       947\n",
            "\n",
            "   micro avg       0.64      0.66      0.65      3853\n",
            "   macro avg       0.50      0.49      0.49      3853\n",
            "weighted avg       0.64      0.66      0.64      3853\n",
            "\n",
            "\n",
            "Average train loss: 0.05364660121580186\n",
            "Training Accuracy: 0.9609639233370914\n",
            "Training F1-Score: 0.7734927690477681\n",
            "Training Precision: 0.737876254180602\n",
            "Training Recall: 0.8127220102618077\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.81      0.89      0.85      6509\n",
            "        MISC       0.58      0.69      0.63      3239\n",
            "         ORG       0.63      0.73      0.67      2014\n",
            "         PER       0.84      0.82      0.83      3440\n",
            "\n",
            "   micro avg       0.74      0.81      0.77     15202\n",
            "   macro avg       0.57      0.63      0.60     15202\n",
            "weighted avg       0.74      0.81      0.78     15202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [10:10<02:32, 152.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9479022925896338\n",
            "Validation F1-Score: 0.7142153239714216\n",
            "Validation Precision: 0.6797186400937867\n",
            "Validation Recall: 0.7524007267064625\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.75      0.86      0.80      1509\n",
            "        MISC       0.50      0.59      0.54       833\n",
            "         ORG       0.58      0.66      0.61       564\n",
            "         PER       0.82      0.78      0.80       947\n",
            "\n",
            "   micro avg       0.68      0.75      0.71      3853\n",
            "   macro avg       0.53      0.58      0.55      3853\n",
            "weighted avg       0.69      0.75      0.72      3853\n",
            "\n",
            "\n",
            "Average train loss: 0.04641156950684252\n",
            "Training Accuracy: 0.9680224008627029\n",
            "Training F1-Score: 0.8092706376747\n",
            "Training Precision: 0.7841322721944599\n",
            "Training Recall: 0.8360742007630575\n",
            "Training Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.85      0.90      0.87      6509\n",
            "        MISC       0.65      0.71      0.68      3239\n",
            "         ORG       0.70      0.77      0.73      2014\n",
            "         PER       0.86      0.87      0.86      3440\n",
            "\n",
            "   micro avg       0.78      0.84      0.81     15202\n",
            "   macro avg       0.61      0.65      0.63     15202\n",
            "weighted avg       0.79      0.84      0.81     15202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 5/5 [12:43<00:00, 152.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9549471033965188\n",
            "Validation F1-Score: 0.7455413212760612\n",
            "Validation Precision: 0.7223168654173765\n",
            "Validation Recall: 0.7703088502465611\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.80      0.86      0.83      1509\n",
            "        MISC       0.56      0.59      0.58       833\n",
            "         ORG       0.62      0.70      0.66       564\n",
            "         PER       0.82      0.82      0.82       947\n",
            "\n",
            "   micro avg       0.72      0.77      0.75      3853\n",
            "   macro avg       0.56      0.60      0.58      3853\n",
            "weighted avg       0.73      0.77      0.75      3853\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>overfitting</td><td>▁▅▆▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▇█</td></tr><tr><td>train_f1</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>train_prec</td><td>▁▄▆▇█</td></tr><tr><td>train_recall</td><td>▁▄▆██</td></tr><tr><td>val_acc</td><td>▁▅▆▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▇█</td></tr><tr><td>val_prec</td><td>▁▄▆▇█</td></tr><tr><td>val_recall</td><td>▁▄▆██</td></tr><tr><td>validation_loss</td><td>█▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>overfitting</td><td>0.06373</td></tr><tr><td>train_acc</td><td>0.96802</td></tr><tr><td>train_f1</td><td>0.80927</td></tr><tr><td>train_loss</td><td>0.04641</td></tr><tr><td>train_prec</td><td>0.78413</td></tr><tr><td>train_recall</td><td>0.83607</td></tr><tr><td>val_acc</td><td>0.95495</td></tr><tr><td>val_f1</td><td>0.74554</td></tr><tr><td>val_prec</td><td>0.72232</td></tr><tr><td>val_recall</td><td>0.77031</td></tr><tr><td>validation_loss</td><td>0.05182</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">playful-rain-54</strong> at: <a href='https://wandb.ai/darijaner/final-results/runs/hina5sn1' target=\"_blank\">https://wandb.ai/darijaner/final-results/runs/hina5sn1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230420_005449-hina5sn1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Test Set:"
      ],
      "metadata": {
        "id": "tiD56vZXbsb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On DarNERcorp_test:"
      ],
      "metadata": {
        "id": "Wg2G6oV3nMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model.state_dict(), '/content/gdrive/MyDrive/Capstone/CAMeL_MIX_GRU_EX2')"
      ],
      "metadata": {
        "id": "o2Z6SkOtHrMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = BERT_BiLSTM_SM(hidden_size = 256, num_layers = 1, p1 = 0.3, p2 = 0.2)\n",
        "#model.load_state_dict(torch.load('/content/gdrive/MyDrive/Capstone/AraBERT_LSTM_EX2', map_location=device))"
      ],
      "metadata": {
        "id": "70YYJaACGuIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "darner_test = pd.read_csv(\"/content/gdrive/MyDrive/annotated_corpus/ner-corpus-darija/DarNERcorp_test.csv\")\n",
        "test_darner_set = ' '.join(darner_test[\"Token\"])\n",
        "tokenized_sentence = tokenizer.encode(test_darner_set)"
      ],
      "metadata": {
        "id": "gIue94ZKH0sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91cd061-b53d-4aeb-afa4-4d73c98603e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17957 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfXEeBcIJwQ-",
        "outputId": "403a4882-f925-4825-865e-3b26eb38f677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_BiLSTM_SM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.3, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.3, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (bilstm): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_labels = []\n",
        "new_tokens = []\n",
        "n = len(tokenized_sentence)//512\n",
        "for i in range(0, n+1):\n",
        "  if (i == n):\n",
        "    batch = tokenized_sentence[i*512:len(tokenized_sentence)]\n",
        "  else:\n",
        "    batch = tokenized_sentence[i*512:i*512+512]\n",
        "  input_ids = torch.tensor([batch]).cuda()\n",
        "  with torch.no_grad():\n",
        "      logits = model(input_ids)\n",
        "  label_indices = np.argmax(logits.to('cpu').numpy(), axis=1)\n",
        "  # join bpe split tokens\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "  for token, label_idx in zip(tokens, label_indices):\n",
        "      if token.startswith(\"##\"):\n",
        "          #adding subword to previous word\n",
        "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "      else:\n",
        "          new_labels.append(tag_values[label_idx])\n",
        "          new_tokens.append(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axBlBko8H29E",
        "outputId": "f321cf33-8d94-4cd7-9d8b-13e2527b24e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-cdd061c866b8>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dar_predictions = [new_labels[1:len(new_labels)-1]]\n",
        "dar_tags = [list(darner_test['Tag'])]"
      ],
      "metadata": {
        "id": "FAmpWVs0H41b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dar_acc, dar_f1, dar_prec, dar_recall, dar_report = get_metrics(dar_tags, dar_predictions)\n",
        "print(dar_acc,'\\n', dar_prec,'\\n', dar_recall,'\\n', dar_f1,'\\n', dar_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl_rPS4QH6kZ",
        "outputId": "1b212c86-88a7-4b22-ce32-f5e2bba09508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9313353566009105 \n",
            " 0.6228448275862069 \n",
            " 0.6784037558685446 \n",
            " 0.6494382022471911 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.73      0.83      0.78       539\n",
            "        MISC       0.55      0.51      0.53       395\n",
            "         ORG       0.50      0.61      0.55       190\n",
            "         PER       0.56      0.66      0.61       154\n",
            "\n",
            "   micro avg       0.62      0.68      0.65      1278\n",
            "   macro avg       0.47      0.52      0.49      1278\n",
            "weighted avg       0.62      0.68      0.65      1278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On mixedNERcorp_test:"
      ],
      "metadata": {
        "id": "GCaOZJirnYMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata as ud\n",
        "def remove_punc(s):\n",
        "  if (len(s) > 1) and s!= '--':\n",
        "    s = ''.join(c for c in s if not ud.category(c).startswith('P'))\n",
        "  return s"
      ],
      "metadata": {
        "id": "u6hdpCzuH9pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixner_test = pd.read_csv(\"/content/gdrive/MyDrive/annotated_corpus/ner-corpus-darija/MixedNERcorp_test.csv\")"
      ],
      "metadata": {
        "id": "yTZJCqP3IBrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = list(mixner_test[\"Token\"])\n",
        "tokens = list(map(remove_punc, tokens))"
      ],
      "metadata": {
        "id": "8g4V8AgdIF_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mixner_set = ' '.join(tokens)\n",
        "tokenized_sentence = tokenizer.encode(test_mixner_set)"
      ],
      "metadata": {
        "id": "lYaz_NJfIJVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_labels = []\n",
        "new_tokens = []\n",
        "n = len(tokenized_sentence)//512\n",
        "for i in range(0, n+1):\n",
        "  if (i == n):\n",
        "    batch = tokenized_sentence[i*512:len(tokenized_sentence)]\n",
        "  else:\n",
        "    batch = tokenized_sentence[i*512:i*512+512]\n",
        "  input_ids = torch.tensor([batch]).cuda()\n",
        "  with torch.no_grad():\n",
        "      logits = model(input_ids)\n",
        "  label_indices = np.argmax(logits.to('cpu').numpy(), axis=1)\n",
        "  # join bpe split tokens\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "  for token, label_idx in zip(tokens, label_indices):\n",
        "      if token.startswith(\"##\"):\n",
        "          #adding subword to previous word\n",
        "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "      else:\n",
        "          new_labels.append(tag_values[label_idx])\n",
        "          new_tokens.append(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiab13QUIK7G",
        "outputId": "5fb0c7f3-edd5-4f49-9c59-e436f9d3002f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-cdd061c866b8>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mix_predictions = [new_labels[1:len(new_labels)-1]]\n",
        "mix_tags = [list(mixner_test['Tag'])]"
      ],
      "metadata": {
        "id": "BUMqKG4WIMu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mix_acc, mix_f1, mix_prec, mix_recall, mix_report = get_metrics(mix_tags, mix_predictions)\n",
        "print(mix_acc,'\\n', mix_prec,'\\n', mix_recall,'\\n', mix_f1,'\\n', mix_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c82vp6NIIQL6",
        "outputId": "383c576b-177b-4ef7-cb00-42f8540852fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9443804336440766 \n",
            " 0.6647325933400605 \n",
            " 0.7395453269716531 \n",
            " 0.7001461405606484 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AD       0.00      0.00      0.00         0\n",
            "         LOC       0.76      0.84      0.80      1215\n",
            "        MISC       0.50      0.51      0.51       638\n",
            "         ORG       0.59      0.68      0.63       649\n",
            "         PER       0.75      0.80      0.77      1061\n",
            "\n",
            "   micro avg       0.66      0.74      0.70      3563\n",
            "   macro avg       0.52      0.57      0.54      3563\n",
            "weighted avg       0.68      0.74      0.71      3563\n",
            "\n"
          ]
        }
      ]
    }
  ]
}